{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a **statistical model** used primarily for **binary classification tasks**. It predicts the probability that a given input belongs to a particular class, making it particularly useful when the output is categorical, like \"yes or no,\" \"success or failure,\" or \"spam or not spam.\" Despite its name, logistic regression is a **classification algorithm**, not a regression algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts of Logistic Regression**\n",
    "\n",
    "1. **Logistic Function (Sigmoid Function):**\n",
    "   - Logistic regression uses the sigmoid function to map predicted values (from \\(-\\infty\\) to \\(+\\infty\\)) to probabilities (between 0 and 1).\n",
    "   - The sigmoid function is defined as:\n",
    "     \\[\n",
    "     \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "     \\]\n",
    "     where \\(z = w^T x + b\\), \\(w\\) is the weights vector, \\(x\\) is the input feature vector, and \\(b\\) is the bias term.\n",
    "\n",
    "2. **Output Interpretation:**\n",
    "   - The output of the sigmoid function is a probability:\n",
    "     \\[\n",
    "     P(y=1|x) = \\sigma(z)\n",
    "     \\]\n",
    "   - If the probability is greater than a threshold (commonly 0.5), the model predicts the class as \\(y=1\\); otherwise, \\(y=0\\).\n",
    "\n",
    "3. **Cost Function:**\n",
    "   - Logistic regression uses the **log-loss (binary cross-entropy)** as its cost function:\n",
    "     \\[\n",
    "     J(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
    "     \\]\n",
    "     where:\n",
    "     - \\(m\\): Number of training examples\n",
    "     - \\(y^{(i)}\\): Actual label (0 or 1)\n",
    "     - \\(\\hat{y}^{(i)}\\): Predicted probability\n",
    "\n",
    "4. **Training Process:**\n",
    "   - The model learns parameters (\\(w\\) and \\(b\\)) using optimization techniques like **Gradient Descent** to minimize the cost function.\n",
    "\n",
    "5. **Multiclass Classification (Extension):**\n",
    "   - For multiclass classification, logistic regression can be extended using:\n",
    "     - **One-vs-Rest (OvR):** Separate binary classifiers for each class.\n",
    "     - **Softmax Regression:** Generalization of logistic regression to handle multiple classes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages:**\n",
    "- Simple and easy to implement.\n",
    "- Computationally efficient.\n",
    "- Provides probabilities, which help in understanding model confidence.\n",
    "- Performs well when the relationship between features and the target variable is approximately linear.\n",
    "\n",
    "### **Limitations:**\n",
    "- Assumes a linear relationship between the independent variables and the log-odds.\n",
    "- Not suitable for complex relationships unless combined with feature engineering.\n",
    "- Sensitive to outliers and irrelevant features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications:**\n",
    "- Email spam detection.\n",
    "- Medical diagnosis (e.g., disease presence).\n",
    "- Customer churn prediction.\n",
    "- Fraud detection in banking.\n",
    "\n",
    "Logistic regression is widely used as a baseline model due to its simplicity and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.625100</td>\n",
       "      <td>1.678124</td>\n",
       "      <td>0.493516</td>\n",
       "      <td>1.290880</td>\n",
       "      <td>-1.114278</td>\n",
       "      <td>1.847020</td>\n",
       "      <td>1.912294</td>\n",
       "      <td>1.357325</td>\n",
       "      <td>0.966041</td>\n",
       "      <td>-3.006921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.064641</td>\n",
       "      <td>4.138629</td>\n",
       "      <td>-1.522415</td>\n",
       "      <td>-2.041705</td>\n",
       "      <td>2.116697</td>\n",
       "      <td>5.281310</td>\n",
       "      <td>3.712587</td>\n",
       "      <td>-0.890254</td>\n",
       "      <td>1.438826</td>\n",
       "      <td>-3.623448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.016313</td>\n",
       "      <td>2.665426</td>\n",
       "      <td>-0.628486</td>\n",
       "      <td>-0.886923</td>\n",
       "      <td>0.992518</td>\n",
       "      <td>1.942381</td>\n",
       "      <td>1.855199</td>\n",
       "      <td>-1.958175</td>\n",
       "      <td>-0.348803</td>\n",
       "      <td>-1.598825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.037282</td>\n",
       "      <td>1.466618</td>\n",
       "      <td>-0.115420</td>\n",
       "      <td>1.170755</td>\n",
       "      <td>-1.458516</td>\n",
       "      <td>1.371440</td>\n",
       "      <td>1.000965</td>\n",
       "      <td>-1.034471</td>\n",
       "      <td>-1.654176</td>\n",
       "      <td>-2.936285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.778385</td>\n",
       "      <td>1.565828</td>\n",
       "      <td>-1.724917</td>\n",
       "      <td>-2.735667</td>\n",
       "      <td>1.215107</td>\n",
       "      <td>1.231249</td>\n",
       "      <td>-0.151824</td>\n",
       "      <td>0.598330</td>\n",
       "      <td>-0.524283</td>\n",
       "      <td>1.252909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0   1.625100   1.678124   0.493516   1.290880  -1.114278   1.847020   \n",
       "1  -0.064641   4.138629  -1.522415  -2.041705   2.116697   5.281310   \n",
       "2   1.016313   2.665426  -0.628486  -0.886923   0.992518   1.942381   \n",
       "3   1.037282   1.466618  -0.115420   1.170755  -1.458516   1.371440   \n",
       "4   0.778385   1.565828  -1.724917  -2.735667   1.215107   1.231249   \n",
       "\n",
       "   Feature_7  Feature_8  Feature_9  Feature_10  Target  \n",
       "0   1.912294   1.357325   0.966041   -3.006921       1  \n",
       "1   3.712587  -0.890254   1.438826   -3.623448       0  \n",
       "2   1.855199  -1.958175  -0.348803   -1.598825       0  \n",
       "3   1.000965  -1.034471  -1.654176   -2.936285       1  \n",
       "4  -0.151824   0.598330  -0.524283    1.252909       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np           \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt             \n",
    "\n",
    "\n",
    "df = pd.read_csv('binary_classification_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n",
      "497\n"
     ]
    }
   ],
   "source": [
    "class0  = (df['Target'] == 0).sum()\n",
    "class1  = (df['Target'] == 1).sum()\n",
    "print(class1)\n",
    "print(class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature_1     0\n",
       "Feature_2     0\n",
       "Feature_3     0\n",
       "Feature_4     0\n",
       "Feature_5     0\n",
       "Feature_6     0\n",
       "Feature_7     0\n",
       "Feature_8     0\n",
       "Feature_9     0\n",
       "Feature_10    0\n",
       "Target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Feature_1   1000 non-null   float64\n",
      " 1   Feature_2   1000 non-null   float64\n",
      " 2   Feature_3   1000 non-null   float64\n",
      " 3   Feature_4   1000 non-null   float64\n",
      " 4   Feature_5   1000 non-null   float64\n",
      " 5   Feature_6   1000 non-null   float64\n",
      " 6   Feature_7   1000 non-null   float64\n",
      " 7   Feature_8   1000 non-null   float64\n",
      " 8   Feature_9   1000 non-null   float64\n",
      " 9   Feature_10  1000 non-null   float64\n",
      " 10  Target      1000 non-null   int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 86.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0     1.625100   1.678124   0.493516   1.290880  -1.114278   1.847020   \n",
       "1    -0.064641   4.138629  -1.522415  -2.041705   2.116697   5.281310   \n",
       "2     1.016313   2.665426  -0.628486  -0.886923   0.992518   1.942381   \n",
       "3     1.037282   1.466618  -0.115420   1.170755  -1.458516   1.371440   \n",
       "4     0.778385   1.565828  -1.724917  -2.735667   1.215107   1.231249   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "995  -1.406303  -1.027162  -1.511787  -2.197166  -0.085131   0.660046   \n",
       "996   1.725603  -1.889881  -0.406775  -2.106446   3.000944  -1.589977   \n",
       "997   2.150153  -1.192165  -2.049206  -2.110471   0.619157  -1.376080   \n",
       "998  -0.686603  -1.914598  -0.121520  -1.940709   2.130283  -2.534632   \n",
       "999   1.288676   0.277453   0.328570  -2.154945   1.264075   1.120435   \n",
       "\n",
       "     Feature_7  Feature_8  Feature_9  Feature_10  Target  \n",
       "0     1.912294   1.357325   0.966041   -3.006921       1  \n",
       "1     3.712587  -0.890254   1.438826   -3.623448       0  \n",
       "2     1.855199  -1.958175  -0.348803   -1.598825       0  \n",
       "3     1.000965  -1.034471  -1.654176   -2.936285       1  \n",
       "4    -0.151824   0.598330  -0.524283    1.252909       0  \n",
       "..         ...        ...        ...         ...     ...  \n",
       "995  -2.095097   1.480886  -0.934154    1.713556       0  \n",
       "996   0.275638  -1.765429   1.297249    6.263591       1  \n",
       "997  -1.545149  -1.302577  -1.285505    4.887055       1  \n",
       "998  -1.714336  -1.421465  -0.028340    4.972418       1  \n",
       "999   0.390176  -1.291040  -2.338172    2.241320       0  \n",
       "\n",
       "[1000 rows x 11 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
